---
title: Cognivoice Backend
emoji: ğŸ¤
colorFrom: blue
colorTo: purple
sdk: docker

app_file: app.py
app_port: 7860
pinned: false
---

# Voice Emotion Detection API Backend

[![Python](https://img.shields.io/badge/python-3.8%2B-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-Backend-green)](https://fastapi.tiangolo.com/)
[![MongoDB](https://img.shields.io/badge/MongoDB-Required-brightgreen)](https://www.mongodb.com/)
[![License](https://img.shields.io/badge/license-Custom-lightgrey)](#license)

---

## ğŸ¤ Real-Time Voice Emotion Recognition API

A robust FastAPI backend for real-time voice emotion recognition using deep learning. Supports user authentication, audio uploads, YouTube audio analysis, and persistent storage with MongoDB.

---

## ğŸš€ Features

- **Real-time emotion detection** from audio and YouTube links
- **User authentication** with JWT tokens
- **Audio storage** with user association
- **Batch processing** for multiple audio samples
- **Multiple audio formats** supported
- **Deep learning model** (CNN-based)
- **Modern, async Python stack**

---

## ğŸ Quickstart

```bash
# 1. Clone the repository
$ git clone <repository-url>
$ cd backend

# 2. Install dependencies (choose one)
$ python install_dependencies.py           # Recommended
$ install_dependencies.bat                 # Windows
$ pip install -r requirements.txt          # Manual

# 3. Configure environment
$ cp .env.example .env                     # Or create .env manually
# Edit .env with your MongoDB URL and secret key

# 4. Start MongoDB (locally or use a cloud instance)

# 5. Launch the API server
$ python start_server.py                   # Or:
$ uvicorn app:app --host 0.0.0.0 --port 8000 --reload
```

---

## ğŸ“š API Overview

### Authentication
- `POST   /api/signup`         â€” Register a new user
- `POST   /api/login`          â€” Login and get JWT token
- `GET    /api/me`             â€” Get current user info

### Emotion Detection
- `POST   /predict-emotion`        â€” Predict emotion from audio data
- `POST   /predict-emotion-batch`  â€” Batch prediction
- `POST   /predict-emotion-file`   â€” Predict from uploaded file
- `POST   /predict-emotion-youtube`â€” Predict from YouTube link (requires auth)
- `GET    /emotions`               â€” List supported emotions

### Audio Management
- `POST   /save-audio`         â€” Save audio with emotion (requires auth)
- `GET    /my-audio`           â€” List your uploaded audios
- `GET    /my-youtube-audio`   â€” List your YouTube audios

### Health & Testing
- `GET    /`                   â€” API status
- `GET    /health`             â€” Health check
- `GET    /test`               â€” Dummy prediction

---

## ğŸ§‘â€ğŸ’» Usage Examples

<details>
<summary><strong>Register a User</strong></summary>

```bash
curl -X POST "http://localhost:8000/api/signup" \
     -H "Content-Type: application/json" \
     -d '{"email": "user@example.com", "password": "password123", "name": "John Doe"}'
```
</details>

<details>
<summary><strong>Login</strong></summary>

```bash
curl -X POST "http://localhost:8000/api/login" \
     -H "Content-Type: application/json" \
     -d '{"email": "user@example.com", "password": "password123"}'
```
</details>

<details>
<summary><strong>Predict Emotion from Audio Data</strong></summary>

```bash
curl -X POST "http://localhost:8000/predict-emotion" \
     -H "Content-Type: application/json" \
     -d '{"audio_data": [0.1, 0.2, 0.3, ...]}'
```
</details>

<details>
<summary><strong>Predict Emotion from YouTube Link (Authenticated)</strong></summary>

```bash
curl -X POST "http://localhost:8000/predict-emotion-youtube" \
     -H "Authorization: Bearer <YOUR_JWT_TOKEN>" \
     -H "Content-Type: application/json" \
     -d '{"youtube_url": "https://www.youtube.com/watch?v=..."}'
```
</details>

---

## ğŸ—‚ï¸ Project Structure

```text
backend/
â”œâ”€â”€ app.py                          # Main FastAPI application
â”œâ”€â”€ improved_inference.py           # Emotion detection model
â”œâ”€â”€ improved_emotion_recognition_model.pth  # Trained model weights
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ start_server.py                 # Startup script
â”œâ”€â”€ test_imports.py                 # Import testing script
â”œâ”€â”€ README.md                       # This file
â””â”€â”€ core/
    â”œâ”€â”€ config.py                   # Configuration settings
    â”œâ”€â”€ security.py                 # Authentication utilities
    â”œâ”€â”€ db/
    â”‚   â””â”€â”€ mongo.py                # Database connections
    â”œâ”€â”€ models/
    â”‚   â””â”€â”€ user.py                 # User model
    â”œâ”€â”€ schemas/
    â”‚   â”œâ”€â”€ user.py                 # User schemas
    â”‚   â””â”€â”€ audio.py                # Audio schemas
    â”œâ”€â”€ services/
    â”‚   â””â”€â”€ user_service.py         # User business logic
    â””â”€â”€ routes/
        â””â”€â”€ user.py                 # User API routes
```

---

## ğŸ› ï¸ Troubleshooting & FAQ

<details>
<summary><strong>ModuleNotFoundError: No module named 'models'</strong></summary>
Update your import paths to use `core.schemas.user` instead of `models.user`.
</details>

<details>
<summary><strong>PyTorch FutureWarning about weights_only</strong></summary>
Add `weights_only=True` to `torch.load()` in your model loading code.
</details>

<details>
<summary><strong>MongoDB connection issues</strong></summary>
- Ensure MongoDB is running
- Check your `MONGO_URL` in the `.env` file
</details>

<details>
<summary><strong>Missing dependencies</strong></summary>
Run `pip install -r requirements.txt` or use the provided install scripts.
</details>

<details>
<summary><strong>How do I test my installation?</strong></summary>
Run:

```bash
python test_imports.py
```
</details>

---

## ğŸ¤ Contributing

Contributions are welcome! To add features or fix bugs:
1. Fork the repository
2. Create a new branch
3. Make your changes
4. Submit a pull request

For major changes, please open an issue first to discuss what you would like to change.

---

## ğŸ“„ License

[Add your license information here]

---

## ğŸ™‹ Support & Contact

- For questions, open an issue on GitHub
- For feature requests, use the Discussions or Issues tab
- For commercial or research inquiries, contact the maintainer

---

## ğŸŒŸ Acknowledgements

- [FastAPI](https://fastapi.tiangolo.com/)
- [PyTorch](https://pytorch.org/)
- [yt-dlp](https://github.com/yt-dlp/yt-dlp)
- [MongoDB](https://www.mongodb.com/)

---

> _Empowering real-time emotion AI for voice applications._ 